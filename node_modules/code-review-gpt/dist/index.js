#!/usr/bin/env node
"use strict";var Et=Object.create;var j=Object.defineProperty;var _t=Object.getOwnPropertyDescriptor;var Ot=Object.getOwnPropertyNames;var Nt=Object.getPrototypeOf,$t=Object.prototype.hasOwnProperty;var l=(e,t)=>()=>(e&&(t=e(e=0)),t);var ie=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),D=(e,t)=>{for(var o in t)j(e,o,{get:t[o],enumerable:!0})},Ct=(e,t,o,r)=>{if(t&&typeof t=="object"||typeof t=="function")for(let n of Ot(t))!$t.call(e,n)&&n!==o&&j(e,n,{get:()=>t[n],enumerable:!(r=_t(t,n))||r.enumerable});return e};var u=(e,t,o)=>(o=e!=null?Et(Nt(e)):{},Ct(t||!e||!e.__esModule?j(o,"default",{value:e,enumerable:!0}):o,e));var ae=ie((xo,Lt)=>{Lt.exports={name:"dotenv",version:"16.3.1",description:"Loads environment variables from .env file",main:"lib/main.js",types:"lib/main.d.ts",exports:{".":{types:"./lib/main.d.ts",require:"./lib/main.js",default:"./lib/main.js"},"./config":"./config.js","./config.js":"./config.js","./lib/env-options":"./lib/env-options.js","./lib/env-options.js":"./lib/env-options.js","./lib/cli-options":"./lib/cli-options.js","./lib/cli-options.js":"./lib/cli-options.js","./package.json":"./package.json"},scripts:{"dts-check":"tsc --project tests/types/tsconfig.json",lint:"standard","lint-readme":"standard-markdown",pretest:"npm run lint && npm run dts-check",test:"tap tests/*.js --100 -Rspec",prerelease:"npm test",release:"standard-version"},repository:{type:"git",url:"git://github.com/motdotla/dotenv.git"},funding:"https://github.com/motdotla/dotenv?sponsor=1",keywords:["dotenv","env",".env","environment","variables","config","settings"],readmeFilename:"README.md",license:"BSD-2-Clause",devDependencies:{"@definitelytyped/dtslint":"^0.0.133","@types/node":"^18.11.3",decache:"^4.6.1",sinon:"^14.0.1",standard:"^17.0.0","standard-markdown":"^7.1.0","standard-version":"^9.5.0",tap:"^16.3.0",tar:"^6.1.11",typescript:"^4.8.4"},engines:{node:">=12"},browser:{fs:!1}}});var G=ie((Ao,f)=>{var ce=require("fs"),V=require("path"),jt=require("os"),Dt=require("crypto"),Mt=ae(),K=Mt.version,Vt=/(?:^|^)\s*(?:export\s+)?([\w.-]+)(?:\s*=\s*?|:\s+?)(\s*'(?:\\'|[^'])*'|\s*"(?:\\"|[^"])*"|\s*`(?:\\`|[^`])*`|[^#\r\n]+)?\s*(?:#.*)?(?:$|$)/mg;function Kt(e){let t={},o=e.toString();o=o.replace(/\r\n?/mg,`
`);let r;for(;(r=Vt.exec(o))!=null;){let n=r[1],s=r[2]||"";s=s.trim();let i=s[0];s=s.replace(/^(['"`])([\s\S]*)\1$/mg,"$2"),i==='"'&&(s=s.replace(/\\n/g,`
`),s=s.replace(/\\r/g,"\r")),t[n]=s}return t}function Gt(e){let t=me(e),o=m.configDotenv({path:t});if(!o.parsed)throw new Error(`MISSING_DATA: Cannot parse ${t} for an unknown reason`);let r=le(e).split(","),n=r.length,s;for(let i=0;i<n;i++)try{let a=r[i].trim(),c=Ht(o,a);s=m.decrypt(c.ciphertext,c.key);break}catch(a){if(i+1>=n)throw a}return m.parse(s)}function Yt(e){console.log(`[dotenv@${K}][INFO] ${e}`)}function qt(e){console.log(`[dotenv@${K}][WARN] ${e}`)}function M(e){console.log(`[dotenv@${K}][DEBUG] ${e}`)}function le(e){return e&&e.DOTENV_KEY&&e.DOTENV_KEY.length>0?e.DOTENV_KEY:process.env.DOTENV_KEY&&process.env.DOTENV_KEY.length>0?process.env.DOTENV_KEY:""}function Ht(e,t){let o;try{o=new URL(t)}catch(a){throw a.code==="ERR_INVALID_URL"?new Error("INVALID_DOTENV_KEY: Wrong format. Must be in valid uri format like dotenv://:key_1234@dotenv.org/vault/.env.vault?environment=development"):a}let r=o.password;if(!r)throw new Error("INVALID_DOTENV_KEY: Missing key part");let n=o.searchParams.get("environment");if(!n)throw new Error("INVALID_DOTENV_KEY: Missing environment part");let s=`DOTENV_VAULT_${n.toUpperCase()}`,i=e.parsed[s];if(!i)throw new Error(`NOT_FOUND_DOTENV_ENVIRONMENT: Cannot locate environment ${s} in your .env.vault file.`);return{ciphertext:i,key:r}}function me(e){let t=V.resolve(process.cwd(),".env");return e&&e.path&&e.path.length>0&&(t=e.path),t.endsWith(".vault")?t:`${t}.vault`}function Ut(e){return e[0]==="~"?V.join(jt.homedir(),e.slice(1)):e}function Wt(e){Yt("Loading env from encrypted .env.vault");let t=m._parseVault(e),o=process.env;return e&&e.processEnv!=null&&(o=e.processEnv),m.populate(o,t,e),{parsed:t}}function Bt(e){let t=V.resolve(process.cwd(),".env"),o="utf8",r=!!(e&&e.debug);e&&(e.path!=null&&(t=Ut(e.path)),e.encoding!=null&&(o=e.encoding));try{let n=m.parse(ce.readFileSync(t,{encoding:o})),s=process.env;return e&&e.processEnv!=null&&(s=e.processEnv),m.populate(s,n,e),{parsed:n}}catch(n){return r&&M(`Failed to load ${t} ${n.message}`),{error:n}}}function Jt(e){let t=me(e);return le(e).length===0?m.configDotenv(e):ce.existsSync(t)?m._configVault(e):(qt(`You set DOTENV_KEY but you are missing a .env.vault file at ${t}. Did you forget to build it?`),m.configDotenv(e))}function Qt(e,t){let o=Buffer.from(t.slice(-64),"hex"),r=Buffer.from(e,"base64"),n=r.slice(0,12),s=r.slice(-16);r=r.slice(12,-16);try{let i=Dt.createDecipheriv("aes-256-gcm",o,n);return i.setAuthTag(s),`${i.update(r)}${i.final()}`}catch(i){let a=i instanceof RangeError,c=i.message==="Invalid key length",p=i.message==="Unsupported state or unable to authenticate data";if(a||c){let d="INVALID_DOTENV_KEY: It must be 64 characters long (or more)";throw new Error(d)}else if(p){let d="DECRYPTION_FAILED: Please check your DOTENV_KEY";throw new Error(d)}else throw console.error("Error: ",i.code),console.error("Error: ",i.message),i}}function Xt(e,t,o={}){let r=!!(o&&o.debug),n=!!(o&&o.override);if(typeof t!="object")throw new Error("OBJECT_REQUIRED: Please check the processEnv argument being passed to populate");for(let s of Object.keys(t))Object.prototype.hasOwnProperty.call(e,s)?(n===!0&&(e[s]=t[s]),r&&M(n===!0?`"${s}" is already defined and WAS overwritten`:`"${s}" is already defined and was NOT overwritten`)):e[s]=t[s]}var m={configDotenv:Bt,_configVault:Wt,_parseVault:Gt,config:Jt,decrypt:Qt,parse:Kt,populate:Xt};f.exports.configDotenv=m.configDotenv;f.exports._configVault=m._configVault;f.exports._parseVault=m._parseVault;f.exports.config=m.config;f.exports.decrypt=m.decrypt;f.exports.parse=m.parse;f.exports.populate=m.populate;f.exports=m});var fe={};D(fe,{configure:()=>Zt});var k,F,Y,Zt,ge=l(()=>{"use strict";k=u(require("fs")),F=u(require("path")),Y=require("child_process"),Zt=async()=>{let e=k.default.readFileSync(F.default.join(__dirname,"pr.yml"),"utf8"),t=F.default.join(process.cwd(),".github","workflows");k.default.mkdirSync(t,{recursive:!0});let o=F.default.join(t,"code-review-gpt.yml");k.default.writeFileSync(o,e,"utf8"),console.log(`Created GitHub Actions workflow at: ${o}`);let r=await import("inquirer"),{apiKey:n}=await r.default.prompt([{type:"input",name:"apiKey",message:"Please input your OpenAI API key:"}]);if(!n){console.log("No API key provided. Please manually add the OPENAI_API_KEY secret to your GitHub repository.");return}try{(0,Y.execSync)("gh auth status || gh auth login",{stdio:"inherit"}),(0,Y.execSync)(`gh secret set OPENAI_API_KEY --body=${n}`),console.log("Successfully added the OPENAI_API_KEY secret to your GitHub repository.")}catch{console.log("It seems that the GitHub CLI is not installed or there was an error during authentication. Don't forget to add the OPENAI_API_KEY to the repo settings/Environment/Actions/Repository Secrets manually.")}}});var I,w,y=l(()=>{"use strict";I=()=>{if(!process.env.OPENAI_API_KEY)throw new Error("OPENAI_API_KEY is not set");return process.env.OPENAI_API_KEY},w=()=>{let e=["GITHUB_SHA","BASE_SHA","GITHUB_TOKEN"].filter(t=>!process.env[t]);if(e.length>0)throw console.error(`Missing environment variables: ${e.join(", ")}`),new Error("One or more GitHub environment variables are not set");return{githubSha:process.env.GITHUB_SHA,baseSha:process.env.BASE_SHA,githubToken:process.env.GITHUB_TOKEN}}});var x,eo,q,he,we,H=l(()=>{"use strict";y();x=require("@actions/github"),eo=(e,t)=>{let o=e.lastIndexOf(t);return o!==-1?e.slice(o+t.length+1):e},q=()=>{let{githubToken:e}=w();if(!e)throw new Error("GITHUB_TOKEN is not set");return e},he=()=>{let e=q(),{payload:t,issue:o}=x.context;if(!t.pull_request){console.warn("Not a pull request. Skipping commenting on PR...");return}let r=(0,x.getOctokit)(e),{owner:n,repo:s,number:i}=o;return{octokit:r,owner:n,repo:s,pull_number:i}},we=async(e,t)=>{try{let o=`${t.feedback.details}

---

${t.signOff}`,{data:r}=await e.rest.pulls.listReviewComments({owner:t.owner,repo:t.repo,pull_number:t.pull_number}),n=eo(t.feedback.fileName,t.repo),s=r.find(i=>i?.path===n&&i?.body?.includes(t.signOff));s?e.rest.pulls.updateReviewComment({owner:t.owner,repo:t.repo,comment_id:s.id,body:o}):await e.rest.pulls.createReviewComment({owner:t.owner,repo:t.repo,pull_number:t.pull_number,body:o,commit_id:t.commit_id,path:n,subject_type:"FILE"})}catch(o){console.error(`Failed to comment on PR for feedback: ${t.feedback.details}. Error: ${o}`)}}});var A,P,U=l(()=>{"use strict";A=require("@actions/github");H();P=async(e,t)=>{try{let o=q(),{payload:r,issue:n}=A.context;if(!r.pull_request){console.warn("Not a pull request. Skipping commenting on PR...");return}let s=(0,A.getOctokit)(o),{owner:i,repo:a,number:c}=n,{data:p}=await s.rest.issues.listComments({owner:i,repo:a,issue_number:c}),d=p.find(Tt=>Tt?.body?.includes(t)),v=`${e}

---

${t}`;d?await s.rest.issues.updateComment({owner:i,repo:a,comment_id:d.id,body:v}):await s.rest.issues.createComment({owner:i,repo:a,issue_number:c,body:v})}catch(o){throw console.error(`Failed to comment on PR: ${o}`),o}}});var W,B,S,ye,be,h=l(()=>{"use strict";W="#### Powered by [Code Review GPT](https://github.com/mattzcarey/code-review-gpt)",B=[{model:"gpt-4",maxPromptLength:21e3},{model:"gpt-4-32k",maxPromptLength:9e4},{model:"gpt-3.5-turbo",maxPromptLength:9e3},{model:"gpt-3.5-turbo-16k",maxPromptLength:45e3}],S=new Set([".js",".ts",".py",".sh",".go",".rs",".tsx",".jsx",".dart"]),ye=new Set(["types"]),be=3});var R,J=l(()=>{"use strict";h();R=e=>{let t=B.find(o=>o.model===e)?.maxPromptLength;if(!t)throw new Error(`Model ${e} not found. Please choose one of ${B.map(o=>o.model)} or make a PR to add a new model.`);return t}});var ve,ke=l(()=>{"use strict";H();ve=async(e,t)=>{let o=he();if(o){let{octokit:r,owner:n,repo:s,pull_number:i}=o,c=(await r.rest.pulls.get({owner:n,repo:s,pull_number:i})).data.head.sha;for(let p of e)we(r,{feedback:p,signOff:t,owner:n,repo:s,pull_number:i,commit_id:c})}}});var Fe,Ie,to,Q,T,X=l(()=>{"use strict";Fe=require("langchain/llms/openai"),Ie=require("ts-retry"),to=3,Q=class{constructor(t){this.model=new Fe.OpenAIChat({openAIApiKey:t.apiKey,modelName:t.modelName,temperature:t.temperature}),this.retryCount=t.retryCount||to}async callModel(t){return this.model.call(t)}async callModelJSON(t){return(0,Ie.retryAsync)(async()=>{let o=await this.model.call(t);return JSON.parse(o)},{maxTry:this.retryCount,onError:o=>{console.error("Error in callModelJSON",o)},onMaxRetryFunc:()=>{throw new Error(`Couldn't call model after ${this.retryCount} tries with prompt: ${t}`)}})}},T=Q});var z,xe,Ae,E=l(()=>{"use strict";z=`As a senior developer, your task is to review a set of pull requests.
You are given a list of filenames and their partial contents, but note that you might not have the full context of the code.

Begin your review by evaluating each code snippet using the LOGAF scale

Do not include the definition of the LOGAF level selected in your review. If a code snippet is at Level 4 or 5, it does not need further review and return to a newline. For snippets at Levels 1 to 3, provide specific feedback.
Focus on code functionality, readability, and performance. Flag any exposed API keys or secrets immediately.

Use markdown formatting for the feedback details. Also do not include the filename or LOGAF level in the feedback details. Ensure the feedback details is brief, concise, accurate, and relevant. Do not give feedback on every possible change, only the most important.
Include brief example code snippets in the feedback details for your changes when you're confident your suggestions are improvements. Use the same programming language as the file under review.
If there are multiple improvements you suggest in the feedback details, use an ordered list to indicate the priority of the changes.

Include the LOGAF level together with the filename of each code snippet in the header, in bold. If the LOGAF level is 4 or 5 do not include it and simply return to a newline.

Format the response in a valid JSON format as a list of feedbacks, where the value is an object containing the filename ("fileName"), LOGAF score ("logafScore") and the feedback ("details"). The schema of the JSON feedback object must be:
{
  "fileName": {
    "type": "string"
  },
  "logafScore": {
    "type": "number"
  },
  "details": {
    "type": "string"
  }
}

The filenames and file contents to review are provided below as a list of JSON objects containing the filename and the file content:

`,xe=`
You are a senior developer and have just reviewed a pull request. This was your feedback:
{feedback}
Please summarise the review using 3 emojis.
`,Ae=`# This file is too large to fully fit in the context window of the model. You will get the changed lines of the file and relevant context found in the file. Only review the changed lines but use the context to inform the review.
Changed lines of the file: {fileContent}
Context: {context} `});var Z,Pe,Se=l(()=>{"use strict";Z=class{constructor(t=[]){this.items=t}enqueue(t,o){let r={priority:o,item:t};this.items.push(r),this.items.sort((n,s)=>n.priority-s.priority)}dequeue(){return this.items.shift()?.item}size(){return this.items.length}peek(){return this.items[0]}getItems(){return this.items.map(t=>t.item)}},Pe=Z});var oo,ee,Re,te=l(()=>{"use strict";oo=e=>`
**LOGAF Level ${e.logafScore} - ${e.fileName}**

${e.details}

`,ee=e=>`
${e.map(oo).join(`
---
`)}
`,Re=(e,t)=>`
${ee(e)}
---
${t}

`});var ro,Te,no,so,Ee,_e=l(()=>{"use strict";h();E();Se();te();ro=async e=>{try{return await e}catch(t){throw console.error("Error in processing prompt",t),t}},Te=async(e,t,o=!0)=>{let r=xe.replace("{feedback}",JSON.stringify(t)),n=await e.callModel(r);return o&&console.log(n),n},no=async(e,t)=>{let o=e.filter(n=>n.logafScore<4),r=new Pe;return o.forEach(n=>{r.enqueue(n,1/(1+n.logafScore)+Math.random()),r.size()>t&&r.dequeue()}),r.getItems()},so=e=>e.reduce((t,o)=>(o.status==="fulfilled"&&t.push(...o.value),t),[]),Ee=async(e,t,o=!0)=>{let r=t.map(a=>e.callModelJSON(a)),n=await Promise.allSettled(r.map(ro)),s=so(n),i=await no(s,be);return o&&console.log(ee(i)),i}});var _,oe=l(()=>{"use strict";y();X();_e();te();_=async(e,t,o=!0)=>{o&&console.info("Asking the experts...");let r=new T({modelName:t,temperature:0,apiKey:I()}),n=await Ee(r,e,o),s=await Te(r,n,o);return{markdownReport:Re(n,s),feedbacks:n}}});var Oe,Ne,re=l(()=>{"use strict";y();Oe=async e=>{if(e){let{githubSha:t,baseSha:o}=w();return`git diff --name-only --diff-filter=AMT ${o} ${t}`}else return"git diff --name-only --diff-filter=AMT --cached"},Ne=async(e,t)=>{if(e){let{githubSha:o,baseSha:r}=w();return`git diff -U0 --diff-filter=AMT ${r} ${o} ${t}`}else return`git diff -U0 --diff-filter=AMT --cached ${t}`}});var $e,Ce,Le=l(()=>{"use strict";$e=require("child_process");re();Ce=async(e,t)=>{let o=await Ne(t,e.fileName);return new Promise((r,n)=>{(0,$e.exec)(o,(s,i,a)=>{if(s)n(new Error(s.message));else if(a)n(new Error(a));else{let c=i.split(`
`).filter(p=>p.startsWith("+")||p.startsWith("-")).filter(p=>!p.startsWith("---")&&!p.startsWith("+++")).join(`
`);r(c)}})})}});var je,io,De,Me=l(()=>{"use strict";je=require("path");h();io={".js":"js",".ts":"js",".py":"python",".go":"go",".rs":"rust",".tsx":"js",".jsx":"js"},De=e=>{let t=(0,je.extname)(e);if(S.has(t))return io[t]}});var Ve,ne,Ke,Ge,Ye=l(()=>{"use strict";Ve=require("langchain/embeddings/openai"),ne=require("langchain/text_splitter"),Ke=require("langchain/vectorstores/memory");Le();Me();E();Ge=async(e,t,o)=>{let r;if(r=await Ce(e,o),r.length>t)return console.error(`The changed lines are ${r.length} which is longer than ${t}. Consider using a model with a larger context window. Slicing the changed lines...`),r=r.slice(0,t),{...e,fileContent:r};let n=De(e.fileName),s;n?s=ne.RecursiveCharacterTextSplitter.fromLanguage(n,{chunkSize:100,chunkOverlap:0}):s=new ne.RecursiveCharacterTextSplitter({chunkSize:100,chunkOverlap:0});let i=await s.createDocuments([r]),a=await Ke.MemoryVectorStore.fromDocuments(i,new Ve.OpenAIEmbeddings),c;c=(await a.similaritySearch(r)).map(d=>d.pageContent).join(`
`),c.length>t&&(console.error(`The context of the changed lines is ${c.length} which is longer than ${t}. Consider using a model with a larger context window. Slicing the context...`),c=c.slice(0,t));let p=Ae.replace("{fileContent}",r).replace("{context}",c);return{...e,fileContent:p}}});var qe,ao,co,lo,O,se=l(()=>{"use strict";qe=require("fs/promises");Ye();E();ao=e=>e.fileName.length+e.fileContent.length,co=async(e,t,o)=>{let r=[],n=[],s=0;for(let i of e){let a=ao(i);if(a>t){console.warn(`File ${i.fileName} is larger than the max prompt length, consider using a model with a larger context window. Attempting to slim the file...`);let c=await Ge(i,t,o);n.push(c)}else s+a>t?(r.push(n),n=[i],s=a):(n.push(i),s+=a)}return n.length>0&&r.push(n),r},lo=async e=>{let t=[];for(let o of e)try{let r=await(0,qe.readFile)(o,"utf8");t.push({fileName:o,fileContent:r})}catch(r){console.error(`Failed to process file ${o}: ${r}`)}return t},O=async(e,t,o)=>{let r=await lo(e),n=t-z.length;return(await co(r,n,o)).map(a=>z+JSON.stringify(a))}});var He,Ue,We,Be=l(()=>{"use strict";He=require("child_process"),Ue=require("path");re();We=async e=>{let t=await Oe(e);return new Promise((o,r)=>{(0,He.exec)(t,(n,s,i)=>{if(n)r(new Error(n.message));else if(i)r(new Error(i));else{let a=s.split(`
`).filter(c=>c.trim()!=="").map(c=>(0,Ue.join)(process.cwd(),c.trim()));o(a)}})})}});var Je,mo,Qe,Xe=l(()=>{"use strict";Je=require("path");h();Be();mo=e=>e.filter(o=>{let r=(0,Je.extname)(o);return S.has(r)&&![...ye].some(n=>o.includes(n))}),Qe=async e=>{console.info("Getting files...");try{let t=await We(e),o=mo(t);return o.length===0&&process.exit(0),o}catch(t){throw console.error(`Failed to get files: ${t}`),t}}});var ze={};D(ze,{review:()=>po});var po,Ze=l(()=>{"use strict";U();J();ke();h();oe();se();Xe();po=async e=>{let t=e.ci,o=e.commentPerFile,r=e.model,n=R(r),s=await Qe(t),i=await O(s,n,t),{markdownReport:a,feedbacks:c}=await _(i,r);t&&!o&&await P(a,W),t&&o&&await ve(c,W)}});var N,et,uo,tt,ot=l(()=>{"use strict";N=require("fs"),et=u(require("path")),uo=e=>{try{let t=(0,N.readFileSync)(e,"utf8");return JSON.parse(t)}catch(t){throw console.error(`Error loading test case: ${e}`),t}},tt=e=>{try{return(0,N.readdirSync)(e).filter(o=>o.endsWith(".json")).map(o=>uo(et.default.join(e,o)))}catch(t){throw console.error(`Error loading test cases from: ${e}`),t}}});var rt,nt,$=l(()=>{"use strict";rt=`
Your role is to help testing a GPT application reviewing code changes. You receive a test case and you need to generate code in typescript corresponding to this test case, even if it follows bad practices or has security issues.
The test cases is formatted as a stringified JSON object with the following properties:
- name: the name of the test case
- description: the description of the test case

The input is the following:
{testCase}

Return the content of a valid typescript file that would pass the test case.
`,nt="#### Tests Powered by [Code Review GPT](https://github.com/mattzcarey/code-review-gpt)"});var st,fo,it,at=l(()=>{"use strict";st=u(require("crypto")),fo="sha256",it=e=>st.default.createHash(fo).update(e).digest("hex")});var C,b,go,ho,ct,lt=l(()=>{"use strict";C=require("fs"),b=u(require("path"));$();at();go=async(e,t)=>{let o=rt.replace("{testCase}",JSON.stringify(e));return(await t.callModel(o)).replace("```typescript","").replace("```","")},ho=async(e,t,o)=>{if(e.snippet)return e;let r=it(e.description);try{return(0,C.readFileSync)(b.default.join(t,`${r}.ts`),"utf8"),{...e,snippet:b.default.join(t,`${r}.ts`)}}catch{console.info(`Snippet not found in cache: ${e.name}. Generating it...`);let s=await go(e,o);return(0,C.writeFileSync)(b.default.join(t,`${r}.ts`),s,"utf8"),{...e,snippet:b.default.join(t,`${r}.ts`)}}},ct=async(e,t,o)=>Promise.all(e.map(r=>ho(r,t,o)))});var g,pt,wo,ut,dt,yo,ft,gt=l(()=>{"use strict";$();g=u(require("chalk")),pt=(r=>(r.PASS="PASS",r.WARN="WARN",r.FAIL="FAIL",r))(pt||{}),wo=e=>e>1-.1?"PASS":e>1-2*.1?"WARN":"FAIL",ut=(e,t)=>{switch(e){case"PASS":return g.default.green(`\u2705 [PASS] - ${t}`);case"WARN":return g.default.yellow(`\u26A0\uFE0F [WARN] - ${t}`);case"FAIL":return g.default.red(`\u274C [FAIL] - ${t}`);default:throw new Error(`Unknown test result: ${e}`)}},dt=(e,t,o,r)=>{let n=wo(r),s=n!=="PASS",i=ut(n,`Test case: ${e.name} - Similarity score: ${r}
`)+(s?yo(e,t,o):"");return{result:n,report:i}},yo=(e,t,o)=>`
 > Test case snippet: ${e.snippet}

===============================================================================

 > Review:
${t}
===============================================================================

> Similar review:
${o}

`,ft=e=>{let t=Object.entries(e).reduce((r,[n,s])=>r+ut(s,`Test case: ${n}`)+`
`,g.default.blue(`
### Test results summary:
`)),o=Object.values(e).reduce((r,n)=>(r[n]++,r),Object.fromEntries(Object.values(pt).map(r=>[r,0])));return t+`
**SUMMARY: ${g.default.green(`\u2705 PASS: ${o.PASS}`)} - ${g.default.yellow(`\u26A0\uFE0F WARN: ${o.WARN}`)} - ${g.default.red(`\u274C FAIL: ${o.FAIL}`)}**
`}});var ht,bo,wt,yt=l(()=>{"use strict";ht=u(require("chalk"));oe();se();gt();bo=async(e,t,o,r,n)=>{if(!e.snippet)throw new Error(`Test case ${e.name} does not have a snippet.`);console.info(ht.default.blue(`Running test case ${e.name}...`));let s=await O([e.snippet],o,n),{markdownReport:i}=await _(s,t,!1),a=await r.similaritySearchWithScore(i,1);if(a.length===0)throw new Error(`No similar reviews found for test case ${e.name}.`);let[c,p]=a[0],{result:d,report:v}=dt(e,i,c.pageContent,p);return console.log(v),d},wt=async(e,t,o,r,n)=>{if(e.length===0)return"No test cases found.";console.info(`Running ${e.length} test cases...
`);let s={};for(let a of e)try{let c=await bo(a,t,o,r,n);s[a.name]=c}catch(c){console.error(`Error running test case ${a.name}:`,c)}let i=ft(s);return console.info(i),i}});var bt,vt,kt,Ft,It,vo,xt,At=l(()=>{"use strict";bt=require("fs"),vt=u(require("path")),kt=require("langchain/document_loaders/fs/text"),Ft=require("langchain/vectorstores/memory"),It=require("langchain/embeddings/openai"),vo=async e=>await new kt.TextLoader(e).load(),xt=async e=>{let t=(0,bt.readdirSync)(e),o=await Promise.all(t.map(async r=>vo(vt.default.join(e,r))));return Ft.MemoryVectorStore.fromDocuments(o.flat(),new It.OpenAIEmbeddings,{})}});var Pt={};D(Pt,{test:()=>ko});var L,ko,St=l(()=>{"use strict";L=u(require("path"));ot();X();y();lt();yt();At();J();U();$();ko=async({ci:e,model:t})=>{let o=R(t),r=tt(L.default.join(__dirname,"cases")),n=await ct(r,L.default.join(__dirname,"cases/.cache"),new T({modelName:t,temperature:0,apiKey:I()})),s=await xt(L.default.join(__dirname,"cases/snapshots")),i=await wt(n,t,o,s,e);e&&await P(i,nt)}});var Rt=u(G());var pe=u(require("yargs")),ue=u(G());ue.default.config();var zt=async()=>{let e=await import("inquirer"),t=[{type:"list",name:"command",message:"What do you want to do?",choices:[{name:"Review the staged files",value:"review"},{name:"Configure the script (Recommended for first time use)",value:"configure"}]}];return(await e.default.prompt(t)).command},de=async()=>{let e=pe.default.option("ci",{description:"Indicate that the script is running on a CI environment",type:"boolean",default:!1}).option("commentPerFile",{description:"Enables feedback to be made on a file-by-file basis.",type:"boolean",default:!1}).option("model",{description:"The model to use for generating the review",type:"string",default:"gpt-4"}).command("review","Review the pull request").command("configure","Configure the script").parseSync();if(e._[0]||(e._[0]=await zt()),e.shouldCommentPerFile&&!e.isCi)throw new Error("The 'commentPerFile' flag requires the 'ci' flag to be set.");return e};Rt.default.config();var Fo=async()=>{let e=await de();switch(e._[0]){case"configure":let{configure:t}=await Promise.resolve().then(()=>(ge(),fe));await t();break;case"review":let{review:o}=await Promise.resolve().then(()=>(Ze(),ze));await o(e);break;case"test":let{test:r}=await Promise.resolve().then(()=>(St(),Pt));await r(e);break;default:console.error("Unknown command"),process.exit(1)}};Fo().catch(e=>{console.error(`Error: ${e}`),process.exit(1)});
